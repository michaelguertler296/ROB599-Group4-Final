# ROB599-Group4-Final 
Final Project: NeRF Gesture Control

Michael Guertler, Sagar Patil, Adithya Ramakrishnan, Tyler Smithline

Watch our final project video:\
[![Watch our final project video](https://img.youtube.com/vi/0wM_abK1gZc/0.jpg)](https://www.youtube.com/watch?v=0wM_abK1gZc)

This project consists of five parts. 
1. In class presentation: https://docs.google.com/presentation/d/1maS8itjtwLz1LGLoe_IzaGOvr054AqAjauwhz4m-Z-4/edit?usp=sharing
2. Paper results reproduction:
   
    TO RUN MIP-NERF:
      - Open the google folder located here: https://drive.google.com/drive/folders/1O-enyC4T3pAI3exF1yl2eRZnq9GG34p0?usp=sharing
      - Open MipNeRF_GestureControl.ipynb
      - Follow instructions to train, visualize, and render mesh from the trained model

3. Algorithmic extension
   
   To run Tiny NeRF Gesture Control:
      - Open the google folder located here: https://drive.google.com/drive/folders/1O-enyC4T3pAI3exF1yl2eRZnq9GG34p0?usp=sharing
      - Open TinyNeRF_GestureControl.ipynb
      - Follow instructions on the notebook to run
  
   To run Mip-NeRF Gesture Control:
      - Open the google folder located here: https://drive.google.com/drive/folders/1O-enyC4T3pAI3exF1yl2eRZnq9GG34p0?usp=sharing
      - Open MipNeRF_GestureControl.ipynb
      - Follow instructions on the notebook to run (as long as you have a trained model already, you can skip the "Mip-NeRF Implementation" section
  
   To run Pre-rendered Gesture Control:
      - Ensure the directory of Output_Images is saved locally (roughly 183 Mb)
      - Set Output_Images file path in track_hand_preload.py
      - Run track_hand_preload.py (you'll need a webcam)

   To run the optimized techniques used on Mip-NeRF: train_fp16.py

   Link to the model weights: https://drive.google.com/drive/folders/1-pUpanjwFtBywLH-jmMWVYZDbx5cbEm5?usp=sharing

5. Final project video: https://youtu.be/0wM_abK1gZc

6. Final project report: https://drive.google.com/file/d/1lUgU2DZJ8YT0YFOpkJzseUgpDOI7cxRE/view?usp=sharing

